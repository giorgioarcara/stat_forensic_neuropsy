lines(1:n.obs, Xs)
abline(h=T)
##########################
# TRUE AND OBSERVED SCORES
##########################
# author: Giorgio Arcara
# ver: 13/10/2023
#################
# DESCRIPTION
###################
# this is a short script to simulate some properties of True and Observed scores
# under assumptions of classical test theory
# X = observed score
# T = True score
# E = error
# E = N(0, sd) # error is distributed "by definition" as a normal variable with 0 mean and a given standard deviation sd
##########################
## simulation paramters
#########################
T = 20 # true score
E.sd = 0.1 # Error  (sd)
n.obs = 200 # number of observations
E = rnorm(1, mean = 0, sd = E.sd)
E
E = rnorm(1, mean = 0, sd = E.sd)
E
E = rnorm(1, mean = 0, sd = E.sd)
E
n.obs = 1000 # number of observations
# data simulation
Xs = NULL
for (iE in 1:n.obs){
E = rnorm(1, mean = 0, sd = E.sd)
Es[iE] = E
Xs[iE] = T + E
}
n.obs = 1000 # number of observations
# data simulation
Xs = NULL
Es = NULL
for (iE in 1:n.obs){
E = rnorm(1, mean = 0, sd = E.sd)
Es[iE] = E
Xs[iE] = T + E
}
Es
mean(Es)
sd(Es)
hist(Es)
40+38+38+6
141000 - 122
45.000/13
45000/13
?factanal
30000/12*2
1500 * 4
0.6* 30000
20000 + 18000 + 16000
20000 + 18000 + 10000 + 12000
53-45
8/53
5342.28 - 45000
50342.28 - 45000
0.2 * 54
0.2 * 54
60 * 30000
library(psych)
?CRV
CVR
?alpha
25 * 40
20 * 40
20 * 8
20 * 36
63*36
63 * 8
63 * 8 + (1.70 * 2)
63 * 8 (1.70 * 2 *)
650 + 580
650 - 580
library(psych)
?Fa
?fa
1389000
1389352
1389352 - 80000
1309352 / 6
218225/2
218225.3 / 3
1189660 / 6
198276 / 2
198276 / 3
1189660 - 8000
ll
1189660 - 80000
1109660 / 6
184943.3 / 2
184943.3 / 3
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
res
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
5 - 10
5 + 1 - (10 + 1)
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
res
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
pract_eff = + 2
res$X2_p = res$X2 + pract_eff
res
points(res$X1, res$X2_p, pch=19)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
points(res$X1, res$X1, pch=20)
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 2
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
#points(res$X1, res$X1, pch=20)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
t.test(res$X1, res$X2, paired=TRUE)
t.test(res$X1, res$X2_p, paired=TRUE)
# create a column that simulate a practice effect
pract_eff = + 3
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
#points(res$X1, res$X1, pch=20)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
# test if there is a significant different between X1 and X2
t.test(res$X1, res$X2, paired=TRUE)
# test if there is a significant different between X1 and X2 with practice effect
t.test(res$X1, res$X2_p, paired=TRUE)
# correlations are unchanged
cor.test(res$X1, res$X2)
cor.test(res$X1, res$X2_p)
# test if there is a significant different between X1 and X2
t.test(res$X1, res$X2, paired=TRUE)
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 100
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
#points(res$X1, res$X1, pch=20)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 100
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
#points(res$X1, res$X1, pch=20)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=c(0, 150))
# create a column that simulate a practice effect
pract_eff = + 100
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
#points(res$X1, res$X1, pch=20)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 3
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
#points(res$X1, res$X1, pch=20)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 3
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
#points(res$X1, res$X1, pch=20)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
# test if there is a significant different between X1 and X2
t.test(res$X1, res$X2, paired=TRUE)
# test if there is a significant different between X1 and X2 with practice effect
t.test(res$X1, res$X2_p, paired=TRUE)
# NOTE: the mean difference approximate what I added with + pract_eff
# correlations are unchanged
cor.test(res$X1, res$X2)
cor.test(res$X1, res$X2_p)
# don't confuse High test-retest with high "stability". It is just high consistency.
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = - 2
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
#points(res$X1, res$X1, pch=20)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
# correlations are unchanged
cor.test(res$X1, res$X2)
cor.test(res$X1, res$X2_p)
# don't confuse
# test if there is a significant different between X1 and X2
t.test(res$X1, res$X2, paired=TRUE)
# test if there is a significant different between X1 and X2 with practice effect
t.test(res$X1, res$X2_p, paired=TRUE)
mean(res$X1)-mean(res$X2_p)
# install.packages("psych")
# install.packages("faux")
rm(list=ls())
library(psych)
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
mat = rnorm_multi(n, mu=mus, r = t_r)
mat
mat = round(rnorm_multi(n, mu=mus, r = t_r))
mat
# the one to be used is ICC 2 (that takes into account absolute agreement of random rater)
ICC(mat)
# the one to be used is ICC 2 (that takes into account absolute agreement of random rater).
# it corresponds to ICC(2,1) agreement in the slides
ICC(mat)
ICC(mat, lmer=FALSE)
# the one to be used is ICC 2 (that takes into account absolute agreement of random rater).
# it corresponds to ICC(2,1) agreement in the slides
ICC(mat)
# here I create a version with a systematic bias in the scores (rater 2)
# are systematically higher but a precise amount
mat_bias = mat
bias = 4
mat_bias[,2]= mat_bias[,2] + 4 # the second rater has a score of + 4 as compared to before.
mat
mat_bias
plot(mat$X1, mat$X2)
# check results when a systematic bias is present in the different versions of ICC
ICC(mat_bias)
# here I create a version with a systematic bias in the scores (rater 2)
# are systematically higher but a precise amount
mat_bias = mat
mat_bias[,2]= mat_bias[,2] + 2 # the second rater has a score of + 4 as compared to before.
# check results when a systematic bias is present in the different versions of ICC
ICC(mat_bias)
cor.test(mat[,1], mat[,2])
cor.test(mat_bias[,1], mat_bias[,2])
n = 20
n.rep = 200
t_r = 0.7
mus = c(20, 20, 20)
ICC21s = NULL
for (iE in 1:n.rep){
res = rnorm_multi(n, mu=mus, sd=c(10, 10, 10), r = t_r)
curr_ICC = ICC(res)
ICC21s[iE] = curr_ICC$results$ICC[2]
}
mean(ICC21s)
hist(ICC21s, xlim=c(0,1))
range(ICC21s)
n = 200
n.rep = 200
t_r = 0.7
mus = c(20, 20, 20)
ICC21s = NULL
for (iE in 1:n.rep){
res = rnorm_multi(n, mu=mus, sd=c(10, 10, 10), r = t_r)
curr_ICC = ICC(res)
ICC21s[iE] = curr_ICC$results$ICC[2]
}
mean(ICC21s)
hist(ICC21s, xlim=c(0,1))
range(ICC21s)
setwd("~/Documents/Lavori Unipd/Corso Neuropsicologia Forense/git_stat_forensic_neuropsy/code")
library(readxl)
library(psych)
rm(list=ls())
items_bin = read.table(file="Example_data/items_bin.txt", sep="\t")
itmes_bin
items_bins_bin
items_bin
# this code obtain proportion of people (rows) obtaining 1
p = apply(items_bin, 2, function(x){sum(x)/length(x)})
# this code obtain proportion of people (rows) obtaining 0
q = 1-p
# calculate number of items
n = dim(items_bin)[2]
# calculate total of the score
tot = apply(items_bin, 1, sum)
# calculate variance of the test
s2_tot = var(tot)
# calculate KR-20 for binary items
KR20_items_bin = (n / (n-1)) * ( (s2_tot - sum(p*q)) / s2_tot)
print(KR20_items_bin)
# here I wrap up a function
# it is the same as above, but with the function the code is handier
KR20_fun <- function(items) {
p = apply(items, 2, function(x){sum(x)/length(x)})
q = 1-p
n = dim(items_bin)[2]
tot = apply(items, 1, sum)
s2_tot = var(tot)
KR20 = (n / (n-1)) * ( (s2_tot - sum(p*q)) / s2_tot)
return(KR20)
}
KR20_fun(items_bin)
10/(10-1)
20/(20-1)
30/(30-1)
40/(40-1)
50/(50-1)
items = read.table(file="Example_data/items.txt", sep="\t")
head(items)
# I remove the column with subject names for simplicity
items = items[,-1]
n = dim(items)[2]
tot = apply(items, 1, sum)
s2_tot = var(tot)
s2 = apply(items, 2, var)
alpha_items = (n / (n-1)) * ( (s2_tot - sum(s2)) / s2_tot)
print(alpha_items)
# create here a function for alpha
alpha_fun = function(items){
n = dim(items)[2]
tot = apply(items, 1, sum)
s2_tot = var(tot)
s2 = apply(items, 2, var)
alpha_items = (n / (n-1)) * ( (s2_tot - sum(s2)) / s2_tot)
return(alpha_items)
}
alpha_fun(items)
alpha_fun(items_bin)
KR20_fun(items_bin)
alpha_fun(items)
## NOTE: alpha is higher as the number of items increases
alpha_res = alpha(items)
print(alpha_res$total$raw_alpha) #alpha for all items
# in the for loop that follows I recalculate alpha dropping everytime one item
# Note that when removing items, alpha is almost always smaller.
for (i in 1:dim(items)[2]){
alpha_res = alpha(items[,-i])
print(alpha_res$total$raw_alpha)
}
# note what happen if add a columns (identical to one of the previous)
items2 = cbind(items, items$Item_1)
alpha_fun(items)
alpha_fun(items2) # alpha increases
alpha(items)
## there are also other alternatives, like omega or GLB (gretaest lower bound)
# Note that they are associated with factor analysis.
omega(items) #
glb(items)
(34000 / 15) * 12
