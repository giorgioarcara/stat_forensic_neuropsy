my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 3
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
#points(res$X1, res$X1, pch=20)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 3
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
#points(res$X1, res$X1, pch=20)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
# test if there is a significant different between X1 and X2
t.test(res$X1, res$X2, paired=TRUE)
# test if there is a significant different between X1 and X2 with practice effect
t.test(res$X1, res$X2_p, paired=TRUE)
# NOTE: the mean difference approximate what I added with + pract_eff
# correlations are unchanged
cor.test(res$X1, res$X2)
cor.test(res$X1, res$X2_p)
# don't confuse High test-retest with high "stability". It is just high consistency.
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = - 2
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
#points(res$X1, res$X1, pch=20)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
# correlations are unchanged
cor.test(res$X1, res$X2)
cor.test(res$X1, res$X2_p)
# don't confuse
# test if there is a significant different between X1 and X2
t.test(res$X1, res$X2, paired=TRUE)
# test if there is a significant different between X1 and X2 with practice effect
t.test(res$X1, res$X2_p, paired=TRUE)
mean(res$X1)-mean(res$X2_p)
# install.packages("psych")
# install.packages("faux")
rm(list=ls())
library(psych)
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
mat = rnorm_multi(n, mu=mus, r = t_r)
mat
mat = round(rnorm_multi(n, mu=mus, r = t_r))
mat
# the one to be used is ICC 2 (that takes into account absolute agreement of random rater)
ICC(mat)
# the one to be used is ICC 2 (that takes into account absolute agreement of random rater).
# it corresponds to ICC(2,1) agreement in the slides
ICC(mat)
ICC(mat, lmer=FALSE)
# the one to be used is ICC 2 (that takes into account absolute agreement of random rater).
# it corresponds to ICC(2,1) agreement in the slides
ICC(mat)
# here I create a version with a systematic bias in the scores (rater 2)
# are systematically higher but a precise amount
mat_bias = mat
bias = 4
mat_bias[,2]= mat_bias[,2] + 4 # the second rater has a score of + 4 as compared to before.
mat
mat_bias
plot(mat$X1, mat$X2)
# check results when a systematic bias is present in the different versions of ICC
ICC(mat_bias)
# here I create a version with a systematic bias in the scores (rater 2)
# are systematically higher but a precise amount
mat_bias = mat
mat_bias[,2]= mat_bias[,2] + 2 # the second rater has a score of + 4 as compared to before.
# check results when a systematic bias is present in the different versions of ICC
ICC(mat_bias)
cor.test(mat[,1], mat[,2])
cor.test(mat_bias[,1], mat_bias[,2])
n = 20
n.rep = 200
t_r = 0.7
mus = c(20, 20, 20)
ICC21s = NULL
for (iE in 1:n.rep){
res = rnorm_multi(n, mu=mus, sd=c(10, 10, 10), r = t_r)
curr_ICC = ICC(res)
ICC21s[iE] = curr_ICC$results$ICC[2]
}
mean(ICC21s)
hist(ICC21s, xlim=c(0,1))
range(ICC21s)
n = 200
n.rep = 200
t_r = 0.7
mus = c(20, 20, 20)
ICC21s = NULL
for (iE in 1:n.rep){
res = rnorm_multi(n, mu=mus, sd=c(10, 10, 10), r = t_r)
curr_ICC = ICC(res)
ICC21s[iE] = curr_ICC$results$ICC[2]
}
mean(ICC21s)
hist(ICC21s, xlim=c(0,1))
range(ICC21s)
setwd("~/Documents/Lavori Unipd/Corso Neuropsicologia Forense/git_stat_forensic_neuropsy/code")
library(readxl)
library(psych)
rm(list=ls())
items_bin = read.table(file="Example_data/items_bin.txt", sep="\t")
itmes_bin
items_bins_bin
items_bin
# this code obtain proportion of people (rows) obtaining 1
p = apply(items_bin, 2, function(x){sum(x)/length(x)})
# this code obtain proportion of people (rows) obtaining 0
q = 1-p
# calculate number of items
n = dim(items_bin)[2]
# calculate total of the score
tot = apply(items_bin, 1, sum)
# calculate variance of the test
s2_tot = var(tot)
# calculate KR-20 for binary items
KR20_items_bin = (n / (n-1)) * ( (s2_tot - sum(p*q)) / s2_tot)
print(KR20_items_bin)
# here I wrap up a function
# it is the same as above, but with the function the code is handier
KR20_fun <- function(items) {
p = apply(items, 2, function(x){sum(x)/length(x)})
q = 1-p
n = dim(items_bin)[2]
tot = apply(items, 1, sum)
s2_tot = var(tot)
KR20 = (n / (n-1)) * ( (s2_tot - sum(p*q)) / s2_tot)
return(KR20)
}
KR20_fun(items_bin)
10/(10-1)
20/(20-1)
30/(30-1)
40/(40-1)
50/(50-1)
items = read.table(file="Example_data/items.txt", sep="\t")
head(items)
# I remove the column with subject names for simplicity
items = items[,-1]
n = dim(items)[2]
tot = apply(items, 1, sum)
s2_tot = var(tot)
s2 = apply(items, 2, var)
alpha_items = (n / (n-1)) * ( (s2_tot - sum(s2)) / s2_tot)
print(alpha_items)
# create here a function for alpha
alpha_fun = function(items){
n = dim(items)[2]
tot = apply(items, 1, sum)
s2_tot = var(tot)
s2 = apply(items, 2, var)
alpha_items = (n / (n-1)) * ( (s2_tot - sum(s2)) / s2_tot)
return(alpha_items)
}
alpha_fun(items)
alpha_fun(items_bin)
KR20_fun(items_bin)
alpha_fun(items)
## NOTE: alpha is higher as the number of items increases
alpha_res = alpha(items)
print(alpha_res$total$raw_alpha) #alpha for all items
# in the for loop that follows I recalculate alpha dropping everytime one item
# Note that when removing items, alpha is almost always smaller.
for (i in 1:dim(items)[2]){
alpha_res = alpha(items[,-i])
print(alpha_res$total$raw_alpha)
}
# note what happen if add a columns (identical to one of the previous)
items2 = cbind(items, items$Item_1)
alpha_fun(items)
alpha_fun(items2) # alpha increases
alpha(items)
## there are also other alternatives, like omega or GLB (gretaest lower bound)
# Note that they are associated with factor analysis.
omega(items) #
glb(items)
(34000 / 15) * 12
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 2
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
#points(res$X1, res$X1, pch=20)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
# test if there is a significant different between X1 and X2
t.test(res$X1, res$X2, paired=TRUE)
# test if there is a significant different between X1 and X2 with practice effect
t.test(res$X1, res$X2_p, paired=TRUE)
# NOTE: the mean difference approximate what I added with + pract_eff
# correlations are unchanged
cor.test(res$X1, res$X2)
cor.test(res$X1, res$X2_p)
# don't confuse High test-retest with high "stability". It is just high consistency.
points(res$X1, res$X1, pch=23)
points(res$X1, res$X1, pch=24)
points(res$X1, res$X1, pch=3)
# install.packages("faux")
rm(list=ls())
library(faux)
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 2
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
points(res$X1, res$X1, pch=3)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
# test if there is a significant different between X1 and X2
t.test(res$X1, res$X2, paired=TRUE)
# test if there is a significant different between X1 and X2 with practice effect
t.test(res$X1, res$X2_p, paired=TRUE)
# NOTE: the mean difference approximate what I added with + pract_eff
# correlations are unchanged
cor.test(res$X1, res$X2)
cor.test(res$X1, res$X2_p)
# don't confuse High test-retest with high "stability". It is just high consistency.
?pch
points(res$X1, res$X1, pch=4)
Ppch
pch
?pch
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 2
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
points(res$X1, res$X1, pch=21)
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect"), bg=c("white", "black"), pch=c(1, 19))
# test if there is a significant different between X1 and X2
t.test(res$X1, res$X2, paired=TRUE)
# test if there is a significant different between X1 and X2 with practice effect
t.test(res$X1, res$X2_p, paired=TRUE)
# NOTE: the mean difference approximate what I added with + pract_eff
# correlations are unchanged
cor.test(res$X1, res$X2)
cor.test(res$X1, res$X2_p)
# don't confuse High test-retest with high "stability". It is just high consistency.
points(res$X1, res$X1, pch=21, bg="gray")
legend("topright", legend=c("original", "with practice effect", "perfect fit X1 = X2"), bg=c("white", "black"), pch=c(1, 19, 21), pt.bg=c("gray"))
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 2
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
points(res$X1, res$X1, pch=21, bg="gray")
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect", "perfect fit (X1 = X2")), bg=c("white", "black"), pch=c(1, 19, 21), pt.bg=c("gray"))
legend("topright", legend=c("original", "with practice effect", "perfect fit (X1 = X2")), bg=c("white", "black"), pch=c(1, 19, 21), pt.bg=c("gray"))
legend("topright", legend=c("original", "with practice effect", "perfect fit (X1 = X2)"), bg=c("white", "black"), pch=c(1, 19, 21), pt.bg=c("gray"))
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-2.5*sd(unlist(res)), +2.5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 2
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
points(res$X1, res$X1, pch=21, bg="gray")
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect", "perfect fit (X1 = X2)"), bg=c("white", "black"), pch=c(1, 19, 21), pt.bg=c("gray"))
# test if there is a significant different between X1 and X2
t.test(res$X1, res$X2, paired=TRUE)
# test if there is a significant different between X1 and X2 with practice effect
t.test(res$X1, res$X2_p, paired=TRUE)
# NOTE: the mean difference approximate what I added with + pract_eff
# correlations are unchanged
cor.test(res$X1, res$X2)
cor.test(res$X1, res$X2_p)
# don't confuse High test-retest with high "stability". It is just high consistency.
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-5*sd(unlist(res)), +5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 2
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
points(res$X1, res$X1, pch=21, bg="gray")
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect", "perfect fit (X1 = X2)"), bg=c("white", "black"), pch=c(1, 19, 21), pt.bg=c("gray"))
# test if there is a significant different between X1 and X2
t.test(res$X1, res$X2, paired=TRUE)
# test if there is a significant different between X1 and X2 with practice effect
t.test(res$X1, res$X2_p, paired=TRUE)
# NOTE: the mean difference approximate what I added with + pract_eff
# correlations are unchanged
cor.test(res$X1, res$X2)
cor.test(res$X1, res$X2_p)
# don't confuse High test-retest with high "stability". It is just high consistency.
?legend
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-5*sd(unlist(res)), +5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 2
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
points(res$X1, res$X1, pch=21, bg="gray")
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect", "perfect fit (X1 = X2)"),
bg=c("white", "black"), pch=c(1, 19, 21), pt.bg=c("gray"), cex=0.5)
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-5*sd(unlist(res)), +5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim)
# create a column that simulate a practice effect
pract_eff = + 2
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
points(res$X1, res$X1, pch=21, bg="gray")
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect", "perfect fit (X1 = X2)"),
bg=c("white", "black"), pch=c(1, 19, 21), pt.bg=c("gray"), cex=0.7)
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-5*sd(unlist(res)), +5*sd(unlist(res)))
# plot x1 and x2
plot(res$X1, res$X2, main=paste("r = ", round(cor(res$X1, res$X2), 2)), ylim=my_ylim, xlab = "test", ylab="retest")
# create a column that simulate a practice effect
pract_eff = + 2
res$X2_p = res$X2 + pract_eff
points(res$X1, res$X2_p, pch=19)
points(res$X1, res$X1, pch=21, bg="gray")
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect", "perfect fit (test = retest)"),
bg=c("white", "black"), pch=c(1, 19, 21), pt.bg=c("gray"), cex=0.7)
# test if there is a significant different between X1 and X2
t.test(res$X1, res$X2, paired=TRUE)
# test if there is a significant different between X1 and X2 with practice effect
t.test(res$X1, res$X2_p, paired=TRUE)
# NOTE: the mean difference approximate what I added with + pract_eff
# correlations are unchanged
cor.test(res$X1, res$X2)
cor.test(res$X1, res$X2_p)
# don't confuse High test-retest with high "stability". It is just high consistency.
# install.packages("faux")
rm(list=ls())
library(faux)
## SIMULATE DATA WITH GIVEN CORRELATION
# sim parameters
n = 50 # number of observations from samples (note: n1 must be equal to n2)
mus=c(20,20) # mean of populations from which samples are drawn
t_r = 0.6 # true underlying correlation
# rnorm_multi (from faux package) simulate random observation from populations with given correlation
res = rnorm_multi(n, mu=mus, r = t_r)
names(res)=c("test", "retest")
# the line below serves to define a larger ylim (the range in y axis), for better plotting below
my_ylim = range(unlist(res)) + c(-5*sd(unlist(res)), +5*sd(unlist(res)))
# plot test and retest
plot(res$test, res$retest, main=paste("r = ", round(cor(res$test, res$retest), 2)), ylim=my_ylim, xlab = "test", ylab="retest")
# create a column that simulate a practice effect
pract_eff = + 2
res$retest_p = res$retest + pract_eff
points(res$test, res$retest_p, pch=19)
points(res$test, res$test, pch=21, bg="gray")
abline(0, 1) # this plots a bisection line where x = y
legend("topright", legend=c("original", "with practice effect", "perfect fit (test = retest)"),
bg=c("white", "black"), pch=c(1, 19, 21), pt.bg=c("gray"), cex=0.7)
# test if there is a significant different between test and retest
t.test(res$test, res$retest, paired=TRUE)
# test if there is a significant different between test and retest with practice effect
t.test(res$test, res$retest_p, paired=TRUE)
# NOTE: the mean difference approximate what I added with + pract_eff
# correlations are unchanged
cor.test(res$test, res$retest)
cor.test(res$test, res$retest_p)
# don't confuse High test-retest with high "stability". It is just high consistency.
