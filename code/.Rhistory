mod9_drop = lm.drop.F(mod9_step, dat=dat9)
summary(mod9_drop)
model_performance(mod9_drop)
Anova(mod9_drop, type="III")
#plot(allEffects((mod9_drop)))
#plot(check_normality(mod9_drop))
#check_predictions(mod9_drop)
#plot(check_collinearity(mod9))
#check_model(mod9_drop)
preds.cont = c("Peso_pre", "BMI_peso_pre", "TSH", "T3", "T4", "TG")
preds.fac = c( "Fumo_dic", "Sale_Si_No...37",  "Supplementate_con_iodio...75", "Latte_almeno_1_gg",  "TIT_DIC", "Naz._dic", "YOGURT_DIC")
dat[, preds.fac] = factorall(dat[, preds.fac])
dep = "Lunghezza"
dat9_b = na.omit(dat[, c(preds.cont, preds.fac, dep)])
dat9_b[,-length(dat9_b)] = scale.cont(dat9_b[, -length(dat9_b)]) # scale everything but the dependent variable
dim(dat9_b)
str(dat9_b)
summary(dat9_b)
mod9_b = lm(Lunghezza~  . , dat9_b)
vif(mod9_b)
mod9_b_step = step(lm(Lunghezza~  . , dat9_b))
mod9_b_drop = lm.drop.F(mod9_b_step, dat=dat9_b)
summary(mod9_b_drop)
model_performance(mod9_b_drop)
Anova(mod9_b_drop, type="III")
#plot(allEffects((mod9_b_drop)))
#plot(check_normality(mod9_b_drop))
#check_predictions(mod9_b_drop)
#plot(check_collinearity(mod9_b))
#check_model(mod9_b_drop)
preds.cont = c("Peso_pre", "BMI_peso_pre")
preds.fac = c( "Fumo_dic", "Sale_Si_No...37",  "Supplementate_con_iodio...75", "Latte_almeno_1_gg",  "TIT_DIC", "Naz._dic", "YOGURT_DIC")
dat[, preds.fac] = factorall(dat[, preds.fac])
dep = "DIC"
dat1bin = na.omit(dat[, c(preds.cont, preds.fac, dep)])
dat1bin[,-length(dat1bin)] = scale.cont(dat1bin[, -length(dat1bin)]) # scale everything but the dependent variable
dim(dat1bin)
str(dat1bin)
summary(dat1bin)
mod1bin = glm(DIC~  . , dat1bin, family=binomial)
vif(mod1bin)
mod1bin_step = step(glm(DIC~  . , dat1bin, family=binomial))
mod1bin_drop = glm.drop.Chisq(mod1bin_step, dat=dat1bin)
summary(mod1bin_drop)
model_performance(mod1bin_drop)
logistic.display(mod1bin_drop)
Anova(mod1bin_drop, type="III")
plot(allEffects((mod1bin_drop)))
# simOut = simulateResiduals(mod1bin_drop)
# plot(simOut)
#plot(check_collinearity(mod1bin))
preds.cont = c("Peso_pre", "BMI_peso_pre", "Iodio_Creat__ug_g_", "TSH", "T3", "T4", "TG")
preds.fac = c( "Fumo_dic", "Sale_Si_No...37",  "Supplementate_con_iodio...75", "Latte_almeno_1_gg",  "TIT_DIC", "Naz._dic", "YOGURT_DIC")
dat[, preds.fac] = factorall(dat[, preds.fac])
dep = "SGA"
dat2bin = na.omit(dat[, c(preds.cont, preds.fac, dep)])
dat2bin[,-length(dat2bin)] = scale.cont(dat2bin[, -length(dat2bin)]) # scale everything but the dependent variable
dim(dat2bin)
str(dat2bin)
summary(dat2bin)
mod2bin = glm(SGA~  . , dat2bin, family=binomial)
vif(mod2bin)
mod2bin_step = step(glm(SGA~  . , dat2bin, family=binomial))
mod2bin_drop = glm.drop.Chisq(mod2bin_step, dat=dat2bin)
summary(mod2bin_drop)
model_performance(mod2bin_drop)
logistic.display(mod2bin_drop)
Anova(mod2bin_drop, type="III")
plot(allEffects((mod2bin_drop)))
#
# simOut = simulateResiduals(mod2bin_drop)
# plot(simOut)
preds.cont = c("Peso_pre", "BMI_peso_pre",  "TSH", "T3", "T4", "TG")
preds.fac = c( "Fumo_dic", "Sale_Si_No...37",  "Supplementate_con_iodio...75", "Latte_almeno_1_gg",  "TIT_DIC", "Naz._dic", "YOGURT_DIC")
dat[, preds.fac] = factorall(dat[, preds.fac])
dep = "SGA"
dat2bin_b = na.omit(dat[, c(preds.cont, preds.fac, dep)])
dat2bin_b[,-length(dat2bin_b)] = scale.cont(dat2bin_b[, -length(dat2bin_b)]) # scale everything but the dependent variable
dim(dat2bin_b)
str(dat2bin_b)
summary(dat2bin_b)
mod2bin_b = glm(SGA~  . , dat2bin_b, family=binomial)
vif(mod2bin_b)
mod2bin_b_step = step(glm(SGA~  . , dat2bin_b, family=binomial))
mod2bin_b_drop = glm.drop.Chisq(mod2bin_b_step, dat=dat2bin_b)
summary(mod2bin_b_drop)
model_performance(mod2bin_b_drop)
logistic.display(mod2bin_b_drop)
Anova(mod2bin_b_drop, type="III")
plot(allEffects((mod2bin_b_drop)))
#
# simOut = simulateResiduals(mod2bin_drop)
# plot(simOut)
preds.cont = c("Peso_pre", "BMI_peso_pre", "Iodio_Creat__ug_g_", "TSH", "T3", "T4", "TG")
preds.fac = c( "Fumo_dic", "Sale_Si_No...37",  "Supplementate_con_iodio...75", "Latte_almeno_1_gg",  "TIT_DIC", "Naz._dic", "YOGURT_DIC")
dat[, preds.fac] = factorall(dat[, preds.fac])
dep = "LBW"
dat3bin = na.omit(dat[, c(preds.cont, preds.fac, dep)])
dat3bin[,-length(dat3bin)] = scale.cont(dat3bin[, -length(dat3bin)]) # scale everything but the dependent variable
dim(dat3bin)
str(dat3bin)
summary(dat3bin)
mod3bin = glm(LBW~  . , dat3bin, family=binomial)
vif(mod3bin)
mod3bin_step = step(glm(LBW~  . , dat3bin, family=binomial))
mod3bin_drop = glm.drop.Chisq(mod3bin_step, dat=dat3bin)
summary(mod3bin_drop)
model_performance(mod3bin_drop)
logistic.display(mod3bin_drop)
Anova(mod3bin_drop, type="III")
plot(allEffects((mod3bin_drop)))
#
# simOut = simulateResiduals(mod3bin_drop)
# plot(simOut)
preds.cont = c("Peso_pre", "BMI_peso_pre", "TSH", "T3", "T4", "TG")
preds.fac = c( "Fumo_dic", "Sale_Si_No...37",  "Supplementate_con_iodio...75", "Latte_almeno_1_gg",  "TIT_DIC", "Naz._dic", "YOGURT_DIC")
dat[, preds.fac] = factorall(dat[, preds.fac])
dep = "LBW"
dat3bin_b = na.omit(dat[, c(preds.cont, preds.fac, dep)])
dat3bin_b[,-length(dat3bin_b)] = scale.cont(dat3bin_b[, -length(dat3bin_b)]) # scale everything but the dependent variable
dim(dat3bin_b)
str(dat3bin_b)
summary(dat3bin_b)
mod3bin_b = glm(LBW~  . , dat3bin_b, family=binomial)
vif(mod3bin_b)
mod3bin_b_step = step(glm(LBW~  . , dat3bin_b, family=binomial))
mod3bin_b_drop = glm.drop.Chisq(mod3bin_b_step, dat=dat3bin_b)
summary(mod3bin_b_drop)
model_performance(mod3bin_b_drop)
logistic.display(mod3bin_b_drop)
Anova(mod3bin_b_drop, type="III")
plot(allEffects((mod3bin_b_drop)))
#
# simOut = simulateResiduals(mod3bin_b_drop)
# plot(simOut)
preds.cont = c("Peso_pre", "BMI_peso_pre", "Iodio_Creat__ug_g_", "TSH", "T3", "T4", "TG")
preds.fac = c( "Fumo_dic", "Sale_Si_No...37",  "Supplementate_con_iodio...75", "Latte_almeno_1_gg",  "TIT_DIC", "Naz._dic", "YOGURT_DIC")
dat[, preds.fac] = factorall(dat[, preds.fac])
dep = "Parto_pretermine"
dat4bin = na.omit(dat[, c(preds.cont, preds.fac, dep)])
dat4bin[,-length(dat4bin)] = scale.cont(dat4bin[, -length(dat4bin)]) # scale everything but the dependent variable
dim(dat4bin)
str(dat4bin)
summary(dat4bin)
mod4bin = glm(Parto_pretermine~  . , dat4bin, family=binomial)
vif(mod4bin)
mod4bin_step = step(glm(Parto_pretermine~  . , dat4bin, family=binomial))
mod4bin_drop = glm.drop.Chisq(mod4bin_step, dat=dat4bin)
summary(mod4bin_drop)
model_performance(mod4bin_drop)
logistic.display(mod4bin_drop)
Anova(mod4bin_drop, type="III")
plot(allEffects((mod4bin_drop)))
#
# simOut = simulateResiduals(mod4bin_drop)
# plot(simOut)
preds.cont = c("Peso_pre", "BMI_peso_pre",  "TSH", "T3", "T4", "TG")
preds.fac = c( "Fumo_dic", "Sale_Si_No...37",  "Supplementate_con_iodio...75", "Latte_almeno_1_gg",  "TIT_DIC", "Naz._dic", "YOGURT_DIC")
dat[, preds.fac] = factorall(dat[, preds.fac])
dep = "Parto_pretermine"
dat4bin_b = na.omit(dat[, c(preds.cont, preds.fac, dep)])
dat4bin_b[,-length(dat4bin_b)] = scale.cont(dat4bin_b[, -length(dat4bin_b)]) # scale everything but the dependent variable
dim(dat4bin_b)
str(dat4bin_b)
summary(dat4bin_b)
mod4bin_b = glm(Parto_pretermine~  . , dat4bin_b, family=binomial)
vif(mod4bin_b)
mod4bin_b_step = step(glm(Parto_pretermine~  . , dat4bin_b, family=binomial))
mod4bin_b_drop = glm.drop.Chisq(mod4bin_b_step, dat=dat4bin_b)
summary(mod4bin_b_drop)
model_performance(mod4bin_b_drop)
logistic.display(mod4bin_b_drop)
mod4bin_2 = update(mod4bin_b_drop, .~.+Peso_pre)
logistic.display(mod4bin_2)
?logistic.display
55/9
500 * 20
0.04/1000
0.04/10000
4000 + (0.22*4000)
30 * 100
96/12
42/12
library(readxl)
dat = as.data.frame(read_excel("movimenti_2024-07-13.xls"))
library(readxl)
dat = as.data.frame(read_excel("movimenti_2024-07-13.xls"))
citation
citation()
20000 / 12
v = as.character(000001949925)
nchar(v)
v
v = character(000001949925)
v
v = c("000001949925")
nchar(v)
0.85*130
36-19
97+23
0.3*120
13*20
56/50
50/56
16/40
44.99 + 29.98 + 41.10 + 27.66 + 348.80
44.99 + 29.98 + 41.10 + 27.66
?pch
14*4
0.4 * 100
.35^2
###############################
# MALINGERING
###############################
rm(list=ls())
## test based on unlikely performance under Random responses
# suppose you have a forced choice test.
n_items = 50
cut_off_rand_success = qbinom(p = 0.05, prob=0.5, size = n_items)
# probability to obtain lesss thatn cut_off_rand_success in n_items
pbinom(cut_off_rand_success, prob=0.5, size = n_items)
# confidence interval around. Is the observed probability different from 0.5? (that is random choice)
prop.test(cut_off_rand_success, n_items, p=0.5, corr=F)
pbinom(cut_off_rand_success, prob=0.5, size = n_items)
print(cut_off_rand_success)
## test based on unlikely performance under Random responses
# suppose you have a forced choice test.
n_items = 100
cut_off_rand_success = qbinom(p = 0.05, prob=0.5, size = n_items)
print(cut_off_rand_success)
setwd("~/Documents/Lavori Unipd/git_corso_statistica_forense/git_stat_forensic_neuropsy/code")
#
rm(list=ls())
library(MASS)
source("R_functions/CGcut.off.bv.R")
#source("R_functions/CGcut.off.bv_table.R")
n.sim.train = 100
# paramters for normative sample
sim_prac = 0
n_size = c(5, 10, 20, 50)
corr = 0.5
err = 1
n_methods = 4 #number of methods, RCI, mRCI, Portaccio, C&G for determining array dimension
MODEL_RES = array(NA, dim=c(length(n_size), n_methods))
colnames(MODEL_RES)=c("RCI", "mRCI", "P10-regr", "C&G06-regr")
row.names(MODEL_RES)=n_size
### LOOP OVER SAMPLE SIZE
for (iN in 1:length(n_size)){
n = n_size[iN]
RCI_res = NULL
mRCI_res = NULL
RCIp_res = NULL # RCI portaccio et al. 2010 version
CG_res= NULL
for (iSim in 1:n.sim.train){
# STEP 1) BUILD
# simulate predictor
xt0xt1 = mvrnorm(n, mu=c(0,0), Sigma=matrix(c(err,corr,corr,err), nrow=2))
xt0 = xt0xt1[,1]
xt1 = xt0xt1[,2] + sim_prac
#plot(xt0, xt1)
# calculate SEdiff
s1 = sd(xt0)
r = cor(xt0, xt1)
SE=s1*(sqrt(1-r))
SEdiff=sqrt(2*(SE^2))
p_eff = mean(xt1)-mean(xt0)
# C & G
dat = data.frame(xt0, xt1)
mod = lm(xt1~xt0, dat)
## STIMULATE TEST DATA
n_test=100
xt0xt1_test = mvrnorm(n_test, mu=c(0,0), Sigma=matrix(c(err,corr,corr,err), nrow=2))
xt0_test = xt0xt1_test[,1]
xt1_test = xt0xt1_test[,2] + sim_prac
dat_test = data.frame(xt0=xt0_test, xt1=xt1_test)
#plot(xt0_test, xt1_test)
## RCI
z = (xt1_test-xt0_test)/SEdiff
RCI_res[iSim] = sum(z <= -1.645)
## MRCI (modified with pract eff)
mz = ((xt1_test-xt0_test) - p_eff)/SEdiff
mRCI_res[iSim] = sum(mz <= -1.645)
# RCI portaccio et al. 2010 version (p. 613)
pred_xt1 = predict(mod, newdata=list(xt0=xt0_test))
mod.err = summary(mod)$sigma
pz = (xt1_test - pred_xt1)/mod.err
RCIp_res[iSim] = sum(pz <= -1.645)
ps = NULL
for (iTest in 1:dim(dat_test)[1]){
res = CGcut.off.bv(controls_data = dat, model= mod, pred = dat_test$xt0[iTest], Yobs = dat_test$xt1[iTest])
ps[iTest]= res$p.obs
}
CG_res[iSim] = sum(ps < 0.05)
}
# total subject tested
RCI_perf = sum(RCI_res)/(n.sim.train*n_test)*100
mRCI_perf = sum(mRCI_res)/(n.sim.train*n_test)*100
RCIp_perf = sum(RCIp_res)/(n.sim.train*n_test)*100
CG_perf= sum(CG_res)/(n.sim.train*n_test)*100
MODEL_RES[iN, ] = c(RCI_perf, mRCI_perf, RCIp_perf, CG_perf)
}
#save(MODEL_RES, file="MODEL_RES_pract.RData")
print(MODEL_RES) # Type 1 ERROR: expected is 5%, for each combination
#
rm(list=ls())
library(MASS)
source("R_functions/CGcut.off.bv.R")
#source("R_functions/CGcut.off.bv_table.R")
n.sim.train = 1000
# paramters for normative sample
sim_prac = 0
n_size = c(5, 10, 20, 50)
corr = 0.5
err = 1
n_methods = 4 #number of methods, RCI, mRCI, Portaccio, C&G for determining array dimension
MODEL_RES = array(NA, dim=c(length(n_size), n_methods))
colnames(MODEL_RES)=c("RCI", "mRCI", "P10-regr", "C&G06-regr")
row.names(MODEL_RES)=n_size
### LOOP OVER SAMPLE SIZE
for (iN in 1:length(n_size)){
n = n_size[iN]
RCI_res = NULL
mRCI_res = NULL
RCIp_res = NULL # RCI portaccio et al. 2010 version
CG_res= NULL
for (iSim in 1:n.sim.train){
# STEP 1) BUILD
# simulate predictor
xt0xt1 = mvrnorm(n, mu=c(0,0), Sigma=matrix(c(err,corr,corr,err), nrow=2))
xt0 = xt0xt1[,1]
xt1 = xt0xt1[,2] + sim_prac
#plot(xt0, xt1)
# calculate SEdiff
s1 = sd(xt0)
r = cor(xt0, xt1)
SE=s1*(sqrt(1-r))
SEdiff=sqrt(2*(SE^2))
p_eff = mean(xt1)-mean(xt0)
# C & G
dat = data.frame(xt0, xt1)
mod = lm(xt1~xt0, dat)
## STIMULATE TEST DATA
n_test=100
xt0xt1_test = mvrnorm(n_test, mu=c(0,0), Sigma=matrix(c(err,corr,corr,err), nrow=2))
xt0_test = xt0xt1_test[,1]
xt1_test = xt0xt1_test[,2] + sim_prac
dat_test = data.frame(xt0=xt0_test, xt1=xt1_test)
#plot(xt0_test, xt1_test)
## RCI
z = (xt1_test-xt0_test)/SEdiff
RCI_res[iSim] = sum(z <= -1.645)
## MRCI (modified with pract eff)
mz = ((xt1_test-xt0_test) - p_eff)/SEdiff
mRCI_res[iSim] = sum(mz <= -1.645)
# RCI portaccio et al. 2010 version (p. 613)
pred_xt1 = predict(mod, newdata=list(xt0=xt0_test))
mod.err = summary(mod)$sigma
pz = (xt1_test - pred_xt1)/mod.err
RCIp_res[iSim] = sum(pz <= -1.645)
ps = NULL
for (iTest in 1:dim(dat_test)[1]){
res = CGcut.off.bv(controls_data = dat, model= mod, pred = dat_test$xt0[iTest], Yobs = dat_test$xt1[iTest])
ps[iTest]= res$p.obs
}
CG_res[iSim] = sum(ps < 0.05)
}
# total subject tested
RCI_perf = sum(RCI_res)/(n.sim.train*n_test)*100
mRCI_perf = sum(mRCI_res)/(n.sim.train*n_test)*100
RCIp_perf = sum(RCIp_res)/(n.sim.train*n_test)*100
CG_perf= sum(CG_res)/(n.sim.train*n_test)*100
MODEL_RES[iN, ] = c(RCI_perf, mRCI_perf, RCIp_perf, CG_perf)
}
n.sim.train = 100 # 100 is suboptimal, but is set to allow for simulations not requiring too much time.
# paramters for normative sample
sim_prac = 0
n_size = c(5, 10, 20, 50)
corr = 0.5
err = 1
n_methods = 4 #number of methods, RCI, mRCI, Portaccio, C&G for determining array dimension
MODEL_RES = array(NA, dim=c(length(n_size), n_methods))
colnames(MODEL_RES)=c("RCI", "mRCI", "P10-regr", "C&G06-regr")
row.names(MODEL_RES)=n_size
### LOOP OVER SAMPLE SIZE
for (iN in 1:length(n_size)){
n = n_size[iN]
RCI_res = NULL
mRCI_res = NULL
RCIp_res = NULL # RCI portaccio et al. 2010 version
CG_res= NULL
for (iSim in 1:n.sim.train){
# STEP 1) BUILD
# simulate predictor
xt0xt1 = mvrnorm(n, mu=c(0,0), Sigma=matrix(c(err,corr,corr,err), nrow=2))
xt0 = xt0xt1[,1]
xt1 = xt0xt1[,2] + sim_prac
#plot(xt0, xt1)
# calculate SEdiff
s1 = sd(xt0)
r = cor(xt0, xt1)
SE=s1*(sqrt(1-r))
SEdiff=sqrt(2*(SE^2))
p_eff = mean(xt1)-mean(xt0)
# C & G
dat = data.frame(xt0, xt1)
mod = lm(xt1~xt0, dat)
## STIMULATE TEST DATA
n_test=100
xt0xt1_test = mvrnorm(n_test, mu=c(0,0), Sigma=matrix(c(err,corr,corr,err), nrow=2))
xt0_test = xt0xt1_test[,1]
xt1_test = xt0xt1_test[,2] + sim_prac
dat_test = data.frame(xt0=xt0_test, xt1=xt1_test)
#plot(xt0_test, xt1_test)
## RCI
z = (xt1_test-xt0_test)/SEdiff
RCI_res[iSim] = sum(z <= -1.645)
## MRCI (modified with pract eff)
mz = ((xt1_test-xt0_test) - p_eff)/SEdiff
mRCI_res[iSim] = sum(mz <= -1.645)
# RCI portaccio et al. 2010 version (p. 613)
pred_xt1 = predict(mod, newdata=list(xt0=xt0_test))
mod.err = summary(mod)$sigma
pz = (xt1_test - pred_xt1)/mod.err
RCIp_res[iSim] = sum(pz <= -1.645)
ps = NULL
for (iTest in 1:dim(dat_test)[1]){
res = CGcut.off.bv(controls_data = dat, model= mod, pred = dat_test$xt0[iTest], Yobs = dat_test$xt1[iTest])
ps[iTest]= res$p.obs
}
CG_res[iSim] = sum(ps < 0.05)
}
# total subject tested
RCI_perf = sum(RCI_res)/(n.sim.train*n_test)*100
mRCI_perf = sum(mRCI_res)/(n.sim.train*n_test)*100
RCIp_perf = sum(RCIp_res)/(n.sim.train*n_test)*100
CG_perf= sum(CG_res)/(n.sim.train*n_test)*100
MODEL_RES[iN, ] = c(RCI_perf, mRCI_perf, RCIp_perf, CG_perf)
}
#save(MODEL_RES, file="MODEL_RES_pract.RData")
print(MODEL_RES) # Type 1 ERROR: expected is 5%, for each combination
#
rm(list=ls())
library(MASS)
source("R_functions/CGcut.off.bv.R")
#source("R_functions/CGcut.off.bv_table.R")
n.sim.train = 100 # 100 is suboptimal, but is set to allow for simulations not requiring too much time.
# paramters for normative sample
sim_prac = 2
n_size = c(5, 10, 20, 50)
corr = 0.5
err = 1
n_methods = 4 #number of methods, RCI, mRCI, Portaccio, C&G for determining array dimension
MODEL_RES = array(NA, dim=c(length(n_size), n_methods))
colnames(MODEL_RES)=c("RCI", "mRCI", "P10-regr", "C&G06-regr")
row.names(MODEL_RES)=n_size
### LOOP OVER SAMPLE SIZE
for (iN in 1:length(n_size)){
n = n_size[iN]
RCI_res = NULL
mRCI_res = NULL
RCIp_res = NULL # RCI portaccio et al. 2010 version
CG_res= NULL
for (iSim in 1:n.sim.train){
# STEP 1) BUILD
# simulate predictor
xt0xt1 = mvrnorm(n, mu=c(0,0), Sigma=matrix(c(err,corr,corr,err), nrow=2))
xt0 = xt0xt1[,1]
xt1 = xt0xt1[,2] + sim_prac
#plot(xt0, xt1)
# calculate SEdiff
s1 = sd(xt0)
r = cor(xt0, xt1)
SE=s1*(sqrt(1-r))
SEdiff=sqrt(2*(SE^2))
p_eff = mean(xt1)-mean(xt0)
# C & G
dat = data.frame(xt0, xt1)
mod = lm(xt1~xt0, dat)
## STIMULATE TEST DATA
n_test=100
xt0xt1_test = mvrnorm(n_test, mu=c(0,0), Sigma=matrix(c(err,corr,corr,err), nrow=2))
xt0_test = xt0xt1_test[,1]
xt1_test = xt0xt1_test[,2] + sim_prac
dat_test = data.frame(xt0=xt0_test, xt1=xt1_test)
#plot(xt0_test, xt1_test)
## RCI
z = (xt1_test-xt0_test)/SEdiff
RCI_res[iSim] = sum(z <= -1.645)
## MRCI (modified with pract eff)
mz = ((xt1_test-xt0_test) - p_eff)/SEdiff
mRCI_res[iSim] = sum(mz <= -1.645)
# RCI portaccio et al. 2010 version (p. 613)
pred_xt1 = predict(mod, newdata=list(xt0=xt0_test))
mod.err = summary(mod)$sigma
pz = (xt1_test - pred_xt1)/mod.err
RCIp_res[iSim] = sum(pz <= -1.645)
ps = NULL
for (iTest in 1:dim(dat_test)[1]){
res = CGcut.off.bv(controls_data = dat, model= mod, pred = dat_test$xt0[iTest], Yobs = dat_test$xt1[iTest])
ps[iTest]= res$p.obs
}
CG_res[iSim] = sum(ps < 0.05)
}
# total subject tested
RCI_perf = sum(RCI_res)/(n.sim.train*n_test)*100
mRCI_perf = sum(mRCI_res)/(n.sim.train*n_test)*100
RCIp_perf = sum(RCIp_res)/(n.sim.train*n_test)*100
CG_perf= sum(CG_res)/(n.sim.train*n_test)*100
MODEL_RES[iN, ] = c(RCI_perf, mRCI_perf, RCIp_perf, CG_perf)
}
#save(MODEL_RES, file="MODEL_RES_pract.RData")
print(MODEL_RES) # Type 1 ERROR: expected is 5%, for each combination
